{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  function Extract_NER():   Extract NER from receiving text list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_NER(ls_textRow):\n",
    "    from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "    \n",
    "    # 載入 自訂詞典\n",
    "    User_Dict = {}\n",
    "    with open(\"KCC Data/Dict/KccDict2020.txt\",\"r\", encoding='utf-8-sig') as UDicts:\n",
    "        for udic in UDicts:\n",
    "            udWord = udic.strip().split(\" \")\n",
    "            if len(udWord) > 1:\n",
    "                User_Dict[udWord[0]] = udWord[1]\n",
    "            else:\n",
    "                User_Dict[udWord[0]] = 10    # 未給定權重者一律賦予預設值 10                \n",
    "    dictionary = construct_dictionary(User_Dict)\n",
    " \n",
    "    ws = WS(\"./data\")\n",
    "    pos = POS(\"./data\")\n",
    "    ner = NER(\"./data\")\n",
    "    \n",
    "    #  ls_segRow = ws(ls_textRow) ------------   without User Dictionary\n",
    "    ls_segRow = ws(ls_textRow, \n",
    "                   sentence_segmentation=True,\n",
    "                   segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\", \"、\"},\n",
    "                   coerce_dictionary = dictionary)\n",
    "    #print(\"ls_segRow = \", ls_segRow)\n",
    "    #print(\"-----------------------------\")\n",
    "    \n",
    "    del ws\n",
    "    del WS\n",
    "    gc.collect()\n",
    "    ls_posRow = pos(ls_segRow)\n",
    "    del pos\n",
    "    del POS\n",
    "    gc.collect()\n",
    "    ls_nerRow = ner(ls_segRow,ls_posRow)\n",
    "    del ner\n",
    "    del NER\n",
    "    gc.collect()\n",
    "    #print(\"ls_nerRow = \", ls_nerRow)\n",
    "    #print(\"-----------------------------\")\n",
    "    return ls_nerRow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data from csv or xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Seq', 'Date', 'Text'], dtype='object')\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016/4/18</td>\n",
       "      <td>馬英九總統昨天上午視察衛武營藝術文化中心，文化部長洪孟啟、工程會副主委顏久榮及高雄市副市長吳...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2016/4/18</td>\n",
       "      <td>日本九州熊本縣接連遭強震襲擊，台灣分別捐贈熊本縣政府和日本政府款項，高雄市長陳菊、台南市長賴...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2016/4/18</td>\n",
       "      <td>壽山動物園為增進動物飼養福祉及保育工作，特設立「高雄市壽山動物園認養辦法」設立動物認養專戶，...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Seq       Date                                               Text\n",
       "0    1  2016/4/18  馬英九總統昨天上午視察衛武營藝術文化中心，文化部長洪孟啟、工程會副主委顏久榮及高雄市副市長吳...\n",
       "1    2  2016/4/18  日本九州熊本縣接連遭強震襲擊，台灣分別捐贈熊本縣政府和日本政府款項，高雄市長陳菊、台南市長賴...\n",
       "2    3  2016/4/18  壽山動物園為增進動物飼養福祉及保育工作，特設立「高雄市壽山動物園認養辦法」設立動物認養專戶，..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#讀檔\n",
    "\n",
    "df_file = pd.read_csv(r\"KCC Data/NewsCisTest.csv\")\n",
    "print(df_file.columns)\n",
    "print(\"-----------------------------------------------------------\")\n",
    "df_file.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Main function:\n",
    "### 2.1  Pass text data to function \"Extract_NER\" by row\n",
    "### 2.2  Integrate every 10 NER return rows into one data frame  \n",
    "### 2.3  Write frame into small csv after droping duplicate, locating class, filtering short NER, sorting by class.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 欄位筆數 =  15\n",
      "------------------------------------------\n",
      "Row No =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row No =  1\n",
      "Row No =  2\n",
      "Row No =  3\n",
      "Row No =  4\n",
      "Row No =  5\n",
      "Row No =  6\n",
      "Row No =  7\n",
      "Row No =  8\n",
      "Row No =  9\n",
      "fileCunt No =  1\n",
      "Row No =  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row No =  11\n",
      "Row No =  12\n",
      "Row No =  13\n",
      "Row No =  14\n",
      "fileCunt No =  2\n",
      "=====================================================================\n",
      "Totle NER Files =  2\n"
     ]
    }
   ],
   "source": [
    "#逐筆傳遞欄位 \"text\"\n",
    "df_text = df_file[\"Text\"]\n",
    "print(\"Text 欄位筆數 = \",len(df_text))\n",
    "print(\"------------------------------------------\")\n",
    "ls_class = list()\n",
    "ls_ner = list()\n",
    "fileCunt = 0\n",
    "rowCunt = 0\n",
    "for i in range(len(df_text)):\n",
    "    rowCunt += 1\n",
    "    ls_dfRow = [df_text[i]]\n",
    "    # print(\"ls_dfRow = \", ls_dfRow)\n",
    "    print(\"Row No = \",str(i))\n",
    "    entity_list = Extract_NER(ls_dfRow)\n",
    "    for j in range(len(entity_list[0])):\n",
    "        seg = entity_list[0].pop()\n",
    "        # print(\"seg = \",seg)\n",
    "        ls_class.append(seg[2])\n",
    "        ls_ner.append(seg[3])\n",
    "    #print(\"===========================================\")\n",
    "    #print(\"ls_class = \",ls_class)\n",
    "    #print(\"ls_ner = \",ls_ner)\n",
    "    # if i == 5 or rowCunt == 2:\n",
    "    if i == (len(df_text)-1) or rowCunt == 10:\n",
    "        fileCunt += 1\n",
    "        extract_df = pd.DataFrame({'Class':ls_class, 'NER':ls_ner})\n",
    "        deDup_df = extract_df.drop_duplicates().copy()\n",
    "        del extract_df\n",
    "        cate_df = deDup_df.loc[deDup_df['Class'].isin(['LOC','PERSON', 'ORG', 'LAW', 'EVENT','GPE','NORP'])].copy()\n",
    "        del deDup_df\n",
    "        filt_df = cate_df[cate_df['NER'].map(len) >= 2].copy()\n",
    "        del cate_df\n",
    "        NER_df = filt_df.sort_values(by=['Class']).copy()\n",
    "        del filt_df\n",
    "        #print(\"__________________________________________________________\")  \n",
    "        #print(NER_df)\n",
    "        print(\"fileCunt No = \",str(fileCunt))\n",
    "        # NER_df.to_csv(r\"News Data\\News NER Out\\\\NewsNER870_\" + str(fileCunt)+ \".csv\")\n",
    "        NER_df.to_csv(r\"ner out/NerTest_\" + str(fileCunt)+ \".csv\")\n",
    "        rowCunt = 0\n",
    "print(\"=====================================================================\")\n",
    "print(\"Totle NER Files = \",fileCunt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrate all csv files into single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3536\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EVENT</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAW</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORP</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>1514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERSON</th>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NER\n",
       "Class       \n",
       "EVENT    128\n",
       "GPE      567\n",
       "LAW       27\n",
       "LOC      194\n",
       "NORP      77\n",
       "ORG     1514\n",
       "PERSON  1029"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "# import pandas as pd\n",
    "\n",
    "# path = r'News Data\\News NER OUT'\n",
    "path = r'ner out'\n",
    "allFiles = glob.glob(\"{}/*.csv\".format(path))\n",
    "li = []\n",
    "for filename in allFiles:\n",
    "    df = pd.read_csv(filename, index_col=0, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "nerFrame = pd.concat(li, axis=0, ignore_index=True)\n",
    "print(len(nerFrame))\n",
    "nerFrame.groupby('Class').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Drop duplicates, group by class and write into csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EVENT</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAW</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORP</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERSON</th>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NER\n",
       "Class      \n",
       "EVENT    61\n",
       "GPE     256\n",
       "LAW      12\n",
       "LOC      96\n",
       "NORP     32\n",
       "ORG     690\n",
       "PERSON  457"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddFrame = nerFrame.drop_duplicates().copy()\n",
    "print(len(ddFrame))\n",
    "ddFrame.groupby('Class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddFrame.sort_values(by=['Class']).to_csv(r\"News Data\\News NER OUT\\\\NewsNER.csv\")\n",
    "ddFrame.sort_values(by=['Class']).to_csv(r\"ner out/NerTest.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
